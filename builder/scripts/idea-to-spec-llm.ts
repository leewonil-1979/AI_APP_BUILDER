import fs from "node:fs";
import path from "node:path";
import { config } from "dotenv";

// Load environment variables from multiple locations
config({ path: path.join(process.cwd(), ".env") });
config({ path: path.join(process.cwd(), "apps", "my_app1", ".env") });

const inPath = process.argv[2];
if (!inPath) {
  console.error("Usage: tsx idea-to-spec-llm.ts <idea.txt>");
  process.exit(1);
}
const idea = fs.readFileSync(inPath, "utf8");
const outPath = path.join(path.dirname(inPath), "app.spec.jsonc");
const apiKey = process.env.OPENAI_API_KEY;
if (!apiKey) {
  console.error("Missing OPENAI_API_KEY");
  console.error("Make sure .env file exists in project root with OPENAI_API_KEY=your_key");
  process.exit(1);
}
async function main() {
  const r = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: { Authorization: `Bearer ${apiKey}`, "Content-Type": "application/json" },
    body: JSON.stringify({
      model: "gpt-4o-mini",
      temperature: 0.2,
      response_format: { type: "json_object" },
      messages: [
        {
          role: "system",
          content:
            "Return ONLY a JSON object matching: {version, idea{title,one_liner?}, scope{must_features[2]}}",
        },
        {
          role: "user",
          content: `Make a minimal spec from this idea:\n${idea}\nRules: version='1.0', exactly 2 must_features.`,
        },
      ],
    }),
  });
  const j = await r.json();
  const txt = j.choices?.[0]?.message?.content ?? "{}";
  const obj = JSON.parse(txt);
  if (!obj.version || !obj.idea?.title || !Array.isArray(obj.scope?.must_features))
    throw new Error("missing fields");
  fs.writeFileSync(outPath, `// generated by LLM\n${JSON.stringify(obj, null, 2)}\n`, "utf8");
  console.log("âœ… wrote", outPath);
}
main().catch((e) => {
  console.error(e);
  process.exit(2);
});
